{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset from Your Documentation\n",
    "\n",
    "![image](./imgs/‎GenAIEnterprises.‎015.png)\n",
    "\n",
    "![image](./imgs/‎GenAIEnterprises.‎016.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import openai\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "def get_api_key(ssm_client, parameter_path):\n",
    "    '''Get the OpenAI API key from the SSM Parameter Store'''\n",
    "    try:\n",
    "        response = ssm_client.get_parameter(\n",
    "            Name=parameter_path,\n",
    "            WithDecryption=True\n",
    "        )\n",
    "        return response['Parameter']['Value']\n",
    "    except ssm_client.exceptions.ParameterNotFound:\n",
    "        raise Exception(f'Parameter {parameter_path} not found in SSM Parameter Store')\n",
    "\n",
    "# Create an SSM client using Boto3\n",
    "region_name = os.getenv('AWS_REGION', 'us-east-1') \n",
    "ssm = boto3.client('ssm', region_name=region_name)\n",
    "\n",
    "openai_api_key = get_api_key(ssm_client=ssm, parameter_path='/openai/api_key')\n",
    "langchain_api_key = get_api_key(ssm_client=ssm, parameter_path='/langchain/api_key')\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\"\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = langchain_api_key\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "llm_model = \"gpt-3.5-turbo-16k\"\n",
    "\n",
    "# Create the vector store and embedding function\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory='docs/chroma/',\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import OpenAIFinetuneEngine\n",
    "\n",
    "finetune_engine = OpenAIFinetuneEngine(\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"data/qa_pairs_openai.jsonl\",\n",
    "    start_job_id=\"ftjob-pXSHvTc91Qo0G5yUpVhqu1gY\"  # if you have an existing job, can specify id here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-pXSHvTc91Qo0G5yUpVhqu1gY at 0x17ada9490> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-pXSHvTc91Qo0G5yUpVhqu1gY\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1694463971,\n",
       "  \"finished_at\": 1694465299,\n",
       "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:neurons-lab::7xi7PZeg\",\n",
       "  \"organization_id\": \"org-f5H7bPv9fgPptJoKt2f4cPHG\",\n",
       "  \"result_files\": [\n",
       "    \"file-Jgqpy0QzqBsVMX2M89b9GcMZ\"\n",
       "  ],\n",
       "  \"status\": \"succeeded\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-uLoAJjacAessJzY7WEcU2oVX\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": 3\n",
       "  },\n",
       "  \"trained_tokens\": 78162,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_engine.get_current_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x17ada8b90> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-pXSHvTc91Qo0G5yUpVhqu1gY\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1694463971,\n",
       "      \"finished_at\": 1694465299,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:neurons-lab::7xi7PZeg\",\n",
       "      \"organization_id\": \"org-f5H7bPv9fgPptJoKt2f4cPHG\",\n",
       "      \"result_files\": [\n",
       "        \"file-Jgqpy0QzqBsVMX2M89b9GcMZ\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-uLoAJjacAessJzY7WEcU2oVX\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 78162,\n",
       "      \"error\": null\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": false\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.FineTuningJob.list(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model Manually\n",
    "## GPT-3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The purpose of a buddy in Made Tech is to provide support and guidance to new employees during their onboarding process."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"Provide answers to questions based on the company handbook to help employees quickly find the information they need. Ensure that your responses are concise and directly address the questions asked without providing additional information.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"What is the purpose of a buddy in the Made Tech company?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "chat = ChatOpenAI(model_name=llm_model, temperature=0)\n",
    "result = chat(messages)\n",
    "\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuned GPT-3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The purpose of a buddy in the Made Tech company is to provide support and guidance to new joiners during their first few weeks. Buddies are responsible for helping new joiners settle in, answering any questions they may have, and assisting them in finding the right people to speak to. They also play a role in introducing new joiners to the company culture and values, as well as organizing social activities to help them get to know their team and other members of the company. Overall, buddies serve as a friendly point of contact for new joiners and aim to make their onboarding experience as smooth and enjoyable as possible."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"Provide answers to questions based on the company handbook to help employees quickly find the information they need. Ensure that your responses are concise and directly address the questions asked without providing additional information.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"What is the purpose of a buddy in the Made Tech company?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm_model = \"ft:gpt-3.5-turbo-0613:neurons-lab::7xi7PZeg\"\n",
    "\n",
    "chat = ChatOpenAI(model_name=llm_model, temperature=0)\n",
    "result = chat(messages)\n",
    "\n",
    "display(Markdown(result.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuned GPT-3.5 Turbo with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "You've been chosen to be a buddy to a new team member - Yay. Here's some guidance to help you find out what's expected.  \n",
      "A buddy is a friend at Made Tech. Someone friendly who helps new team members connect and find their way, especially in their first 3 months with us when everything is new to them.  \n",
      "Being a buddy is a really important way to help a new person integrate into Made Tech.\n",
      "When we're back in the office, you will show them all the good lunch places near the office, take them out for a coffee or lunch and help them find their way in the local area.  \n",
      "As we're working remotely currently, most or all of your interactions will happen on video calls which we call 'coffee chats'.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "At Made Tech, mentorship enables Made Tech staff with the opportunity to provide guidance and support to people in the wider tech community. Mentees are able to gain new knowledge and support and develop and enhance their skills.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Made Tech are an [AWS Advanced Consulting Partner](https://partners.amazonaws.com/partners/001E0000016ppWOIAY/Made%20Tech) and require all Made Tech employees to create a user account within the AWS Partner Portal as part of their onboarding process for a number of reasons.  \n",
      "1. Access to free AWS Partner Training materials.\n",
      "2. Linking employees personal AWS Certification accounts to our Partner account.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "If you are a Made Tech employee, please refer to this [guide for Software Engineers on how to pair](https://docs.google.com/document/d/1x8fVCx-FB-VU_1EHbGU6yLDn1fDyfa5R/edit?usp=sharing&ouid=113960202795862454830&rtpof=true&sd=true).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "Thank you for signing up to be a Made Tech mentor. Here’s a little guide for how to prepare and go about the sessions.  \n",
      "The point of doing this is to provide an opportunity for people to expand on their coding skills from professionals in the industry, but also to provide those looking to enter the industry with an insight into what it can be like.  \n",
      "As a mentor, you will be supporting people at various stages on their tech journeys, these could be people who applied to the Academy, or people who are members of various tech communities or networks. You get to help someone by sharing both your technical and non-technical knowledge and experience, helping them grow on their fundamentals or understand some tricky concepts.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The purpose of a buddy in the Made Tech company is to help new team members connect and find their way, especially in their first 3 months with the company when everything is new to them. Buddies are friendly individuals who provide support and guidance to new team members, both in-person when back in the office (e.g., showing them good lunch places, going out for coffee or lunch, helping them navigate the local area) and remotely through video calls or \"coffee chats\". Being a buddy is an important role in helping new team members integrate into Made Tech."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n",
    "\n",
    "question = \"What is the purpose of a buddy in the Made Tech company?\"\n",
    "llm_model = \"ft:gpt-3.5-turbo-0613:neurons-lab::7xi7PZeg\"\n",
    "#llm_model =\"gpt-3.5-turbo\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=llm_model, temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={'fetch_k': 5, 'k': 7}),\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "result = qa_chain(question)\n",
    "pretty_print_docs(result[\"source_documents\"])\n",
    "display(Markdown(result[\"result\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
